def setpackage{x} = require{merge{'package ', x}}
def ux = i32
def __le{x:T, y:T & 'u'==quality{T}} = fail{'no unsigned comparison'}
def __lt{x:T, y:T & 'u'==quality{T}} = fail{'no unsigned comparison'}
def __ge{x:T, y:T & 'u'==quality{T}} = fail{'no unsigned comparison'}
def __gt{x:T, y:T & 'u'==quality{T}} = fail{'no unsigned comparison'}
def __shr{x:T, y  & 'u'==quality{T}} = emit{T, 'op >>>', x, y}
def __shl{x:T, y & issigned{T} & width{T}<32} = cast_i{T, promote{i32,x} << y}
def __min{a:T, b:T & (T==i32) | (T==i64)} = emit{T, 'Math.min', a, b}
def __max{a:T, b:T & (T==i32) | (T==i64)} = emit{T, 'Math.max', a, b}

local def canon_i{T} = T
local def canon_i{T & isprim{T}} = if ('f'==quality{T}) T else ty_s{T}
local def canon_i{V & vece{V}} = [vcount{V}]canon_i{eltype{V}}

def reinterpret{T, x & ~knum{x}} = fail{'no reinterpret ', T, x}
def reinterpret{T, x:T} = x
def reinterpret{R, x:X & R!=X & width{R}==width{X} & typekind{R}=='primitive' & typekind{X}=='primitive' & quality{R}!='f' & quality{X}!='f'} = emit{R, '', x}
def java_cast{T, x} = {
  if (knum{x}) reinterpret{T, x}
  else emit{T, '^cast', x}
}
def java_cast{T, x:T} = x
def cast_i{T, x} = java_cast{T, x}
def promote{T, x:X} = fail{'bad promote', T, x}
def promote{T, x:T} = x
def promote{T, x:X & isprim{T} & isprim{X} & T>X & quality{X}!='u'} = java_cast{T,x}
def promote{T, x:X & isprim{T} & isprim{X} & T>X & quality{T}=='u'} = java_cast{T,x} & ((1<<width{X}) - 1)
def promote{T, x:(u1) & T>u1} = emit{T, '^boolpromote', x}
local def isarr{A} = typekind{A}=='pointer'
if (0) {
  require{'import sun.misc.Unsafe'}
  require{'import java.lang.reflect.Field'}
  require{'^unsafe'}
  local def unsafe = 'MY_UNSAFE'
  local def typecase{T, upper} = select{match(canon_i{T}) {
    {(i8)}  => tup{'Byte',   'BYTE'}
    {(i16)} => tup{'Short',  'SHORT'}
    {(i32)} => tup{'Int',    'INT'}
    {(i64)} => tup{'Long',   'LONG'}
    {(f32)} => tup{'Float',  'FLOAT'}
    {(f64)} => tup{'Double', 'DOUBLE'}
  }, upper}
  local def offset{T} = emit{i32, '', merge{'Unsafe.ARRAY_', typecase{T,1}, '_BASE_OFFSET'}}
  local def calc_eoff{E, eoff} = offset{E} + eoff * (width{E}/8)
  local def putget{op, T} = merge{unsafe, '.', op, typecase{T,0}}
  def load{T, arr:A, eoff & isprim{T}} = {
    def E = eltype{A}
    emit{T, putget{'get',T}, arr, calc_eoff{E,eoff}}
  }
  
  # replace load/store ops with ones that are unsafe; doesn't seem good
  # def load{arr:A, eoff & isarr{A}} = load{eltype{A}, arr, eoff}
  # def store{arr:A, eoff, v & isarr{A} & can_promote{eltype{A}, v}} = {
  #   def E = eltype{A}
  #   emit{void, putget{'put',E}, arr, calc_eoff{E,eoff}, v}
  # }
} else {
  def LD = [16]i8 # using [8]i8 is a lot of times slower
  def load{(i64), arr:*i8, eoff} = extract{re_el{i64, load{LD, arr, eoff}}, 0}
}

def static_arr{E, vs & ktup{vs}} = emit{*E, '^arr', 'static', 'init', ...vs}
def object_arr{E, vs & ktup{vs}} = emit{*E, '^arr', 'object', 'init', ...vs}
def static_arr{E, n & knum{n}} = emit{*E, '^arr', 'static', 'len', n}
def object_arr{E, n & knum{n}} = emit{*E, '^arr', 'object', 'len', n}
def function_arr{E, n & knum{n}} = emit{*E, '^atbegin', '^newarray', n}

def jint{T} = (T==i32) | (T==u32)
def popc{x:T & canon_i{T}==i64} = emit{i32, 'Long.bitCount', x}
def popc{x:T & canon_i{T}==i32} = emit{i32, 'Integer.bitCount', x}
def clz{n==0, x:T & canon_i{T}==i32} = emit{i32, 'Integer.numberOfLeadingZeros', x}
def clz{n==0, x:T & canon_i{T}==i64} = emit{i32, 'Long.numberOfLeadingZeros', x}
def ctz{x:T & canon_i{T}==i64} = emit{i32, 'Long.numberOfTrailingZeros', x}
def ctz{x:T & intty{T} & width{T}<=32} = emit{i32, 'Integer.numberOfTrailingZeros', x}


# vector things
require{'import jdk.incubator.vector.*'}

def reinterpret{R, x:X & R!=X & vece{R} & vece{X} & width{R}==width{X}} = {
  if (canon_i{R} == canon_i{X}) emit{R, '', x}
  else emit{R, merge{'method reinterpretAs', match(canon_i{eltype{R}}) {
    {(i8)}=>'Bytes'
    {(i16)}=>'Shorts'
    {(i32)}=>'Ints'
    {(i64)}=>'Longs'
  }}, x}
}

local def lanewise{x:T, y, op} = emit{T, 'method lanewise', x, merge{'VectorOperators.',op}, y}

def __add{x:T, y:T & vece{T}} = emit{T, 'method add', x, y}
def __sub{x:T, y:T & vece{T}} = emit{T, 'method sub', x, y}
def __mul{x:T, y:T & vece{T}} = emit{T, 'method mul', x, y}

def __min{x:T, y:T & vecs{T}} = emit{T, 'method min', x, y}
def __max{x:T, y:T & vecs{T}} = emit{T, 'method max', x, y}

def __or  {x:T, y:T & veci{T}} = emit{T, 'method or',  x, y}
def __and {x:T, y:T & veci{T}} = emit{T, 'method and', x, y}
def andnot{x:T, y:T & veci{T}} = lanewise{x, y, 'AND_NOT'}
def __xor {x:T, y:T & veci{T}} = lanewise{x, y, 'XOR'}
def __not{x:T & veci{T}} = emit{T, 'method not', x}

def __shr{x:T, y & vecs{T}} = lanewise{x, y, 'ASHR'}
def __shr{x:T, y & vecu{T}} = lanewise{x, y, 'LSHR'}
def __shl{x:T, y & veci{T}} = lanewise{x, y, 'LSHL'}

def __subs{x,y} = fail{'no saturating arith'}

local def cmpop{T, n} = merge{'VectorOperators.', if('u'==quality{eltype{T}}) 'UNSIGNED_' else '', n}
local def elq{T, E} = eltype{T} == E
local def elq{T, T} = 1
def __gt{x:T, y:VE & veci{T} & elq{T,VE}} = emit{tomask{T}, 'method compare', x, cmpop{T, 'GT'}, y}
def __ge{x:T, y:VE & veci{T} & elq{T,VE}} = emit{tomask{T}, 'method compare', x, cmpop{T, 'GE'}, y}
def __lt{x:T, y:VE & veci{T} & elq{T,VE}} = emit{tomask{T}, 'method compare', x, cmpop{T, 'LT'}, y}
def __le{x:T, y:VE & veci{T} & elq{T,VE}} = emit{tomask{T}, 'method compare', x, cmpop{T, 'LE'}, y}
def __eq{x:T, y:T & vece{T}} = emit{tomask{T}, 'method compare', x, 'VectorOperators.EQ', y}
def __ne{x:T, y:T & vece{T}} = emit{tomask{T}, 'method compare', x, 'VectorOperators.NE', y}


local def vecTypeStr{V} = merge{match(eltype{V}) {
  {(i64)} => 'Long'; {(i32)} => 'Int'; {(i16)} => 'Short'; {(i8)} => 'Byte'
  {(u64)} => 'Long'; {(u32)} => 'Int'; {(u16)} => 'Short'; {(u8)} => 'Byte'
}, 'Vector'}
local def species{V} = merge{vecTypeStr{V}, '.SPECIES_', fmtnat{width{V}}}

def homMask{x:T} = emit{u64, 'method toLong', x}
def broadcast{T, e & vece{T}} = emit{T, 'castmethod broadcast', T, species{T}, promote{eltype{T}, e}}

local def arroff{A, V, off} = if (vece{V} and isarr{A} and eltype{A}==eltype{V}) 1 else 0
def load{V, arr:A, off & arroff{A, V, off}} = emit{V, 'castmethod fromArray', V, species{V}, arr, off}
def store{arr:A, off, x:V & arroff{A, V, off}} = emit{void, 'method intoArray', x, arr, off}
def extract{v:V, i & vecb{V}} = emit{u1, 'method laneIsSet', v, i}
def extract{v:V, i & vece{V}} = emit{eltype{V}, 'method lane', v, i}

def gather{E, arr:P, ptrOff, idxs:V, scale & scale*8 == width{E}} = {
  def buf = getenv{'buf_i32'}
  store{buf, 0, idxs}
  def n = vcount{V}
  def V = [n]E
  emit{V, 'method fromArray', species{V}, arr, ptrOff, buf, 0}
}

# horrible emulation of an unaligned little-endian gather
def gather{(i64), arr:*i8, ptrOff, idxs:V, scale==1 & V==[4]i32} = {
  idxs2:= idxs + ptrOff
  make{[4]i64, each{{i} => load{i64, arr, extract{idxs2,i}}, range{4}}}
}

local def exp_op{op, me, a:T, b:T} = {
  if (T==[2]u64 or T==[2]i64) { # horribly slow without this workaround; still slow with this
    show{'//warn warning: using slow v_eq/v_ne'}
    def buf = getenv{'make_buf'}{u64, 4}
    r:= fold{me, each{{c} => { store{buf,0,ty_u{c}}; load{[4]u64,buf,0} }, tup{a,b}}}
    store{buf, 0, r}
    load{[2]u64, buf, 0}
  } else {
    emit{ty_u{T}, 'castmethod toVector', ty_u{T}, op{a, b}}
  }
}
def v_eq{a:T, b:T} = exp_op{==, v_eq, a, b}
def v_ne{a:T, b:T} = exp_op{!=, v_ne, a, b}

def full_eq{a:T, b:T} = emit{u1, 'method equals', a, b}
def full_ne{a:T, b:T} = ~(a===b)

def shuf_type{V} = [1]V

def l128shufb_ident{T} = range{vcount{T}}
def l128shufb{v:V, i:I} = {
  def B = re_el{i8, V}
  V~~emit{B, 'method selectFrom', B~~i, B~~v}
}
def l128shufb_mask{T} = vcount{T}-1

def shuf{L, v:V, ...is & width{L}==width{V}} = {
  def S = shuf_type{L}
  V~~emit{L, 'method rearrange', L~~v, emit{S, '^atbegin', 'method shuffleFromValues', species{L}, ...is}}
}

# significant speedup by replacing a [2]u64 shuf with an equivalent [4]u32 one
# default: ~60ns; first one here: ~4.4ns; second one: ~0.85ns
def shuf{([2]u64), x:V, ...is & width{V}==128 & tuplen{is}==2} = shuf{[4]u32, x, ...join{each{{i}=>i*2 + tup{0,1}, is}}}
def shuf{([2]u64), x:V, i, i & width{V}==128} = V~~[2]u64**extract{[2]u64~~x, i}

def make{V, els & vcount{V}==tuplen{els}} = {
  if (fold{&, each{knum, els}}) {
    def buf = static_arr{eltype{V}, els}
    load{V, buf, 0}
  } else {
    def buf = getenv{'make_buf'}{eltype{V}, vcount{V}}
    each{{i,e} => store{buf,i,e}, range{tuplen{els}}, els}
    load{V, buf, 0}
  }
}

def pair{a:T, b:T} = {
  def D = [vcount{T}*2]eltype{T}
  def buf = getenv{'make_buf'}{eltype{D}, vcount{D}}
  store{buf, 0, a}
  store{buf, vcount{T}, b}
  load{D, buf, 0}
}
def halves{a:T} = {
  def H = [vcount{T}/2]eltype{T}
  def buf = getenv{'make_buf'}{eltype{T}, vcount{T}}
  store{buf, 0, a}
  tup{load{H,buf,0}, load{H,buf,vcount{H}}}
}

def display{a, b} = {}
def printstr{a} = {}
def printf{...vs} = if (tuplen{vs}>0) {
  def syms = each{{v} => ~ksym{v}, vs}
  def space = merge{each{
    {i, s0} => s0 & select{syms,i+1},
    range{tuplen{vs}-1}, slice{syms,0,-1}
  }, 0}
  each{
    {o} => emit{void, 'System.out.print', if (ksym{o}) merge{'"',o,'"'} else o},
    merge{...each{{n, s} => tup{n, ...s**' '}, vs, space}}
  }
}
def lprintf{...vs} = printf{...vs, '\n'}