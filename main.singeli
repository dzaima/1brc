include 'singeli-java/base'

def bulk = 32 # byte count for maximum-parallel ops
def exp_bulk = 16 # maximum name length to handle in fast path
def interleaved = 4 # number of semicolon searches to interleave
def bufmax = 1000 # TODO 2^n-proc_bulk
def takes0{x} = match(x) { {(32)} => 3 } # max number of semicolons fast path of search should handle in N bytes
def HASH = u32 # full hash
def HASHV = [4]HASH # buckets to search

# shift down by n bytes in the low 8 bytes of each 128-bit lane
def l128_shrb8{a:V, n} = l128shrb{a,n} # unused as-is, but could be better on some architectures
def l128_shrb8{a:V, n} = a >>{u64} (n*8)

def proc_bulk = 4 # number of records to handle in a processing iteration
def VIX = [proc_bulk]vptr_store

config playground = 0
def one = playground
(if (not playground) require{'header.h'})
def lpf1{...vs} = if (one) lprintf{...vs}
def  pf1{...vs} = if (one)  printf{...vs}
def lps1{...vs} = if (one) printstr{...vs}

# define "a +{i32} b" etc to reinterpret as the element, do the op, and cast back
local def retype_cond{C} = isprim{C}|veca{C}
local def retype_type{C, T} = if (veca{C}) C else re_el{C, T}
local def autoexp{V,e} = if (veca{V} and (knum{e} or hastype{e,eltype{V}})) 1 else 0
local def extend vecfn{op} = {
  def op{C & retype_cond{C}} = {
    def c{T} = retype_type{C, T}
    def me{a:V, b & autoexp{c{V},b}} = V~~op{c{V}~~a, c{V}**b}
    def me{a, b:V & autoexp{c{V},a}} = V~~op{c{V}**a, c{V}~~b}
    def me{a:V,    b:c{V}} = V~~op{c{V}~~a, b}
    def me{a:c{V}, b:V   } = V~~op{a, c{V}~~b}
    def me{a:V,    b:V   } = V~~op{c{V}~~a, c{V}~~b}
  }
  def op{a:V, b   & autoexp{V,b}} = op{a, V**b}
  def op{a,   b:V & autoexp{V,a}} = op{V**a, b}
}
extend ({...f}=>each{vecfn,f}){
  __add, __sub, __mul, __div, __mod,
  __eq, __ne, __gt, __ge, __lt, __le,
  __and, __or, __xor, v_eq, v_ne,
  __min, __max, __subs, __adds
}
local def extend retypeShift{op} = {
  def op{C & retype_cond{C}}{a:T, b} = T~~op{retype_type{C,T}~~a, b}
}
extend retypeShift{__shr}
extend retypeShift{__shl}
def l128_upper_u64{x:T & width{T}==128} = shuf{[2]u64, x, 1, 1}
def l128_upper_u64{x:T & width{T}==256} = shuf{[4]u64, x, 1, 1, 3, 3}
def cycle_make{V, ...vs} = make{V, cycle{vcount{V}, vs}}

def iter_count{bulk} = (bufmax/(interleaved*takes0{bulk})) >> 0
oper ~* re_el infix right 55

def bufmax2 = bufmax+proc_bulk

def periter = bulk * interleaved * iter_count{bulk}
fn core_1brc_buf_elts() : ux = bufmax2 * interleaved
fn core_1brc_periter() : ux = periter
export{'core_1brc_buf_elts', core_1brc_buf_elts}
export{'core_1brc_periter', core_1brc_periter}


def hash_vec{x:V & eltype{V}==i8} = {
  def HX = HASH~*V
  hv:= HX~~x
  hv^= l128_upper_u64{hv}
  hv^= l128_shrb8{hv,4}
  hv^= hv >>{i32} 16
  # hv = HX~~madd{i16~*hv, i16~*hv}
  hv # &{u32} 255 # for testing hash collision behavior
}

fn hash_1brc(arr:*i8) : HASH = extract{hash_vec{load{[exp_bulk]i8, arr, ux~~0}}, 0}
export{'hash_1brc', hash_1brc}



def dt_sum = 0
def dt_num = 1
def dt_min = 2
def dt_max = 3
def DATA = if (is_java) i64 else i32
fn core_1brc(
  ident:i32,
  bufdata:*ux,
  
  hash_mask:HASH, # map length (power of two), minus 1
  
  # indexed by masked hash
  map_exp:*i8,    # chunks of exp_bulk
  map_hash:*HASH, # full hash
  map_data:*DATA,  # chunks of 4: min, max, sum, count
  
  inp:*i8,
  inpOff:ux
) : void = @withbufs(object_arr) {
  def takes = takes0{bulk}
  
  def ri = range{interleaved}
  def bufstart{i} = i * bufmax2
  def bufcs = each{{i} => { pos:ux = bufstart{i} }, ri}
  bufEnds:*ux = object_arr{ux, interleaved}
  
  ########## SEMICOLON SEARCH ##########
  def inpcs = each{{i} => { pos:ux = inpOff + i*bulk }, ri}
  @for(i to iter_count{bulk}) {
    def ms0 = each{{inpc} => homMask{load{[bulk]i8, inp, inpc} == 59}, inpcs}
    
    def ms = each{{x} => {m:=x}, ms0}
    def adv_mask{bufc, inpc, m, j, m0tmp} = {
      m2:= m & (m-1)
      store{bufdata, bufc+j, inpc+ctz{m}} # TODO move to_store to a vectorized add at the end?
      m = m2
    }
    @for_const(j to takes) {
      each{{inpc, bufc, m,m0} => adv_mask{bufc, inpc, m, j, m0}, inpcs, bufcs, ms,ms0}
    }
    
    each{{i, m0, m, bufc, inpc} => {
      pop:= popc{m0}
      if (rare{pop > takes}) { # TODO move to an outer if that checks if any is over?
        bufc+= takes
        do {
          adv_mask{bufc, inpc, m, 0, m0}
          bufc+= 1
        } while (m != 0)
      } else {
        bufc+= pop
      }
      inpc+= bulk*interleaved
    }, ri, ms0, ms, bufcs, inpcs}
  }
  
  each{{i, bufc} => {
    store{bufEnds, i, bufc}
    @for_const(i to proc_bulk) store{bufdata, bufc+i, exp_bulk} # allow reading a record at a past-the-end buf entry
  }, ri, bufcs}
  
  
  
  ########## PROCESSING ##########
  # temperature parsing stuff
  def VI64 = [proc_bulk]i64
  def VI16 = i16~*VI64
  def VI8  =  i8~*VI64
  temp_buf:*i16 = object_arr{i16, vcount{VI16}**0}
  tail_mask:*i8 = static_arr{i8, merge{exp_bulk**0, exp_bulk ** -1}}
  # search & update stuff
  def VX = [exp_bulk]i8
  failbuf:= object_arr{ux, bufmax*interleaved*2}
  failposS:ux = 0
  failposC:ux = 0
  
  @for(buf_i to interleaved) {
    bufS:= bufstart{buf_i}
    bufE:= load{bufEnds, buf_i}
    
  ########## PROCESSING ITERATION ##########
    retctr:ux = 0
    def buf_end = makelabel{}
    while (bufS < bufE) { # proc_bulk records per iteration
      ########## NUMBER PARSING ##########
      idxs:= load{VIX, bufdata, bufS}
      nums:= VI8~~gather{i64, inp, 1, idxs, 1} # each 8-byte group is a number
      nums = nums &{u64} 7r0xff # make last byte 0
      
      off:= VI8~~(v_eq{nums, 46} >>{i32} 23) &{u64} 3 # get offset of '.' minus 1 within i64 (i.e. '1.1'→0, '10.2'→1, '-1.2'→1, '-12.3'→2)
      def low8_64 = l128shufb_ident{VI8} - cycle{vcount{VI8}, range{8}} # shuf nums for low byte within i64
      off = l128shufb{off, make{VI8, low8_64}} # expand the low byte of each i64 to each byte
      # display{'off1', off}
      
      def to_digits{v} = { # convert to digits, mapping '\n' and '.' to 0
        if (is_java) __max{i8}{v -{i8} 48, 0} # no saturating ops
        else __subs{u8}{v, 48}
      }
      
      # nums     off1       off2A    aligned    off2B    aligned16
      # 01234567 01234567   702????? 01234567   01234567 01234567
      # 8.5↩ABC^ 00000000   702????? ^.85↩???   **0*2*?? ^^8^5^??
      # 17.1↩AB^ 11111111   013????? 1.71↩???   0*1*3*?? 1^7^1^??
      # 12.8↩AB^ 11111111   013????? 1.28↩???   0*1*3*?? 1^2^8^??
      # -10.1↩A^ 22222222   124????? 1.01↩???   1*2*4*?? 1^0^1^??
      # '^'='\0'                                 '*'=7
      each16:= if (not is_java and width{VI16}==256) {
        off+= make{VI8, cycle{vcount{VI8}, tup{-1,0,2,-1, -1,-1,-1,-1}} + low8_64}
        # display{'off2A', off}
        if (is_java) off&= l128shufb_mask{VI8}
        aligned:= l128shufb{nums, off}
        aligned = to_digits{aligned}
        t16:= madd{u8~*aligned, cycle_make{VI8,  10,1,1,0}}
        t32:= madd{t16,         cycle_make{VI16, 10,1}}
        VI16~~t32
      } else {
        
        off|= cycle_make{VI8, 0,7, 0,7, 0,7, 7,7}
        off+= make{VI8, cycle{vcount{VI8}, tup{-1,0, 0,0, 2,0, 0,0}} + low8_64}
        if (is_java) off&= l128shufb_mask{VI8}
        # display{'off2B', off}
        aligned16:= VI16~~l128shufb{nums, off}
        
        aligned16 = to_digits{aligned16}
        
        aligned16*= cycle_make{VI16, 100,10,1,0} # multiply by the place
        aligned16 = aligned16 + (aligned16 >>{u64} 32) # sum the parts
        aligned16 = aligned16 + (aligned16 >>{u64} 16)
      }
      
      # negate negative numbers
      neg:= VI16~~v_ne{u16}{v_eq{nums, 45}, 0}
      each16^= neg
      each16-= neg
      # each16 is now [16]i16~~{num0, *, *, *, num1, *, *, *, num2, *, *, *, num3, *, *, *}
      store{temp_buf, 0, each16} # make it available for easy lookup in the loop
      
      
      
      ########## HASHING ##########
      def left = bufE - bufS
      
      # hashes two rows of names at a time on native; on Java that's slower :/
      def hashn = if (is_java) 1 else 2
      def VVX = [hashn * exp_bulk]i8
      
      def get_temp{ij} = load{temp_buf, ij*4}
      def to_fail{ij} = {
        # log fail, to be processed later (so codegen of the fast path isn't pessimized by the presence of a call here)
        store{failbuf, failposC, load{bufdata, bufS + ij}}
        store{failbuf, failposC+1, cast_i{ux, get_temp{ij}}}
        failposC+= 2
      }
      
      @for (i to proc_bulk/hashn) {
        def ib = i*hashn
        def mask_newline{v:T} = if (width{T}==256) {
          def V64 = u64~*T
          a:= V64~~v_eq{v, 10}
          l:= if (is_java) l128_upper_u64{a} & cycle_make{V64, -1,0}
          else l128shrb{a, 8}
          a|= v_ne{l, 0}
          if (0) {
            a|= l128_shrb8{a, 1}
            a|= l128_shrb8{a, 2}
            a|= l128_shrb8{a, 4}
            v &~ T~~a
          } else {
            a = tree_fold{|, each{{c}=>a>>c, 4 + 16*range{4}}}
            v & T~~v_eq{T~~a, 0}
          }
        } else {
          mc:= homMask{v == 10}
          c:ux = exp_bulk
          if (likely{mc!=0}) c = clz{exp_bulk, mc}
          v & load{VX, tail_mask, c}
        }
        
        # load names
        def {parts, total} = {
          def for_vs{G} = @for_const(j to hashn) {
            off:= load{bufdata, bufS + ib + j}
            G{load{VX, inp, off-exp_bulk}}
          }
          if (is_java or hashn==1) {
            def parts = for_vs{mask_newline}
            tup{parts, pair{parts}}
          } else {
            def total = mask_newline{pair{for_vs{{x}=>x}}}
            tup{halves{total}, total}
          }
        }
        
        # hash
        def VHX = HASH~*VVX
        hv:VHX = hash_vec{total}
        
        def update{ij, idx} = {
          dataoff:= idx*4
          temp:= promote{DATA, get_temp{ij}}
          def upd{k, G} = {
            def p = tup{map_data, dataoff+k}
            store{...p, G{load{...p}}}
          }
          if (is_java) upd{dt_min, {v} => __min{v, temp}}
          else         upd{dt_min, {v} => __max{v, -temp}}
          upd{dt_max, {v} => __max{v, temp}}
          upd{dt_sum, {v} => v + temp}
          upd{dt_num, {v} => v + 1}
        }
        
        if (hashn==2 and not is_java) {
          hx:= shuf{VHX, hv, 0,0,0,0, 4,4,4,4}
          idxv:= hv & hash_mask
          idxs:= each{{i} => promote{ux, extract{idxv,i}}, range{hashn} * 4}
          hashes:= pair{each{{idx} => load{HASHV, map_hash, idx}, idxs}}
          m:= homMask{hashes == hx}
          m2:= m & (m-1)
          if (rare{m2 == 0}) {
            def {i0,i1} = idxs
            def c = ctz{m}
            idxs = tup{i0+c, i1+c-vcount{HASHV}}
          } else {
            idxs = each{{idx,m} => idx+ctz{m}, idxs, tup{m,m2>>vcount{HASHV}}}
          }
          each{{j, idx} => {
            def ij = ib + j
            if (rare{ij >= left}) goto{buf_end}
            exp:= load{VX, map_exp, idx*exp_bulk}
            if (exp !== select{parts,j}) {
              to_fail{ij}
            } else {
              update{ij, idx}
            }
          }, range{hashn}, idxs}
        } else @for_const (j to hashn) {
          def ij = ib + j
          if (rare{ij >= left}) goto{buf_end}
          hash:= extract{hv, j*4}
          
          idx:= cast_i{ux, hash&hash_mask}
          m:= homMask{hash == load{HASHV, map_hash, idx}}
          if (rare{m==0}) { # no matching hash value
            to_fail{ij}
          } else {
            idx+= ctz{m}
            exp:= load{VX, map_exp, idx*exp_bulk}
            if (exp !== select{parts,j}) {
              to_fail{ij}
            } else {
              update{ij, idx}
            }
          }
        }
      }
      
      if (one and ++retctr >= 7) return{}
      
      bufS+= vcount{VIX}
    }
    setlabel{buf_end}
  }
  
  # handle fails
  if (not playground) while (failposS < failposC) {
    def end = load{failbuf, failposS}
    def temp = ty_s{load{failbuf, failposS+1}}
    failposS+= 2
    def case{which, start, ...hash} = {
      if (is_java) emit{void, merge{'main.Main.failed_',which}, ident, start, end, temp, ...hash}
      else         emit{void, merge{          'failed_',which},        start, end, temp, ...hash}
    }
    
    def v0 = load{VX, inp, end-exp_bulk}
    m:= homMask{v0 == 10}
    if (likely{m==0}) {
      start:= end
      do {
        start-= exp_bulk
        m = homMask{load{VX, inp, start-exp_bulk} == 10}
      } while (m==0)
      case{'long', start-clz{exp_bulk, m}}
    } else {
      c:= clz{exp_bulk, m}
      case{'short', end-c, extract{hash_vec{v0 & load{VX, tail_mask, c}},0}}
    }
  }
}
export{'core_1brc', core_1brc}

(if (is_java or playground) {
  fn minibench(ai8:*i8, ai16:*i16, ai32:*i32, ai64:*i64) : void = @withbufs(object_arr) {
    def VI8  = [16]i8;   def VU8  =  u8~*VI8
    def VI16 = i16~*VI8; def VU16 = u16~*VI8
    def VI32 = i32~*VI8; def VU32 = u32~*VI8
    def VI64 = i64~*VI8; def VU64 = u64~*VI8
    @for (i to 1000) {
      def V = VI8
      def arr = match(elwidth{V}) { {(8)}=>ai8; {(16)}=>ai16; {(32)}=>ai32; {(64)}=>ai64 }
      
      def j = i * vcount{V}
      v:= load{V, arr, j}
      
      store{arr, j, V~~v}
    }
  }
  export{'minibench',minibench}
})
