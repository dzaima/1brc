include 'singeli-java/base'
include 'util/functionize'

def bulk = if (is_arm) 16 else 32 # byte count for maximum-parallel ops
def exp_bulk = 16 # maximum name length to handle in fast path
def interleaved = if (is_arm) 4 else 3 # number of semicolon searches to interleave
def semi_bulk = if (is_arm) 32 else bulk # bytes processed per single buffer
def bufmax = 1000
def takes0{x} = match(x) { {(16)} => 2; {(32)} => 3 } # max number of semicolons fast path of search should handle in N bytes
def HASH = u32 # full hash
def HASHV = [if (is_java or is_arm) 4 else 8]HASH # buckets to search
def placeholder_idx{} = emit{u64,'','hash_mask_max'} + vcount{HASHV}

def proc_bulk = 4 # number of records to handle in a processing iteration
def VIX = [proc_bulk]vptr_store

# shift down by n bytes in the low 8 bytes of each 128-bit lane
def l128_shrb8{a:V, n} = l128shrb{a,n} # unused as-is, but could be better on some architectures
def l128_shrb8{a:V, n} = a >>{u64} (n*8)

config playground = 0
def one = playground
(if (not playground) require{'header.h'})
def lpf1{...vs} = if (one) lprintf{...vs}
def  pf1{...vs} = if (one)  printf{...vs}
def lps1{...vs} = if (one) printstr{...vs}

# define "a +{i32} b" etc to reinterpret as the element, do the op, and cast back
local def retype_cond{C} = isprim{C}|veca{C}
local def retype_type{C, T} = if (veca{C}) C else re_el{C, T}
local def autoexp{V,e} = if (veca{V} and (knum{e} or hastype{e,eltype{V}})) 1 else 0
local def extend vecfn{op} = {
  def op{C & retype_cond{C}} = {
    def c{T} = retype_type{C, T}
    def me{a:V, b & autoexp{c{V},b}} = V~~op{c{V}~~a, c{V}**b}
    def me{a, b:V & autoexp{c{V},a}} = V~~op{c{V}**a, c{V}~~b}
    def me{a:V,    b:c{V}} = V~~op{c{V}~~a, b}
    def me{a:c{V}, b:V   } = V~~op{a, c{V}~~b}
    def me{a:V,    b:V   } = V~~op{c{V}~~a, c{V}~~b}
  }
  def op{a:V, b   & autoexp{V,b}} = op{a, V**b}
  def op{a,   b:V & autoexp{V,a}} = op{V**a, b}
}
extend ({...f}=>each{vecfn,f}){
  __add, __sub, __mul, __div, __mod,
  __eq, __ne, __gt, __ge, __lt, __le,
  __and, __or, __xor, v_eq, v_ne,
  __min, __max, __subs, __adds,
}
local def extend retypeShift{op} = {
  def op{C & retype_cond{C}} = {
    def c{T} = retype_type{C, T}
    def me{a:V,    b:c{V}}   = V~~op{c{V}~~a, b}
    def me{a:c{V}, b:V   }   = V~~op{a, c{V}~~b}
    def me{a:V,    b:V   }   = V~~op{c{V}~~a, c{V}~~b}
    def me{a:V, b & knum{b}} = V~~op{c{V}~~a, b}
  }
}
extend retypeShift{__shr}
extend retypeShift{__shl}
def l128_upper_u64{x:T & width{T}==128} = shuf{[2]u64, x, 1, 1}
def l128_upper_u64{x:T & width{T}==256} = shuf{[4]u64, x, 1, 1, 3, 3}
def cycle_make{V, ...vs} = make{V, cycle{vcount{V}, vs}}

def iter_count{bulk} = (bufmax/(interleaved*takes0{bulk})) >> 0
oper ~* re_el infix right 55

def bufmax2 = bufmax+proc_bulk

def periter = interleaved * semi_bulk * iter_count{semi_bulk}
fn core_1brc_buf_elts() : ux = bufmax2 * interleaved
fn core_1brc_periter() : ux = periter
export{'core_1brc_buf_elts', core_1brc_buf_elts}
export{'core_1brc_periter', core_1brc_periter}

tail_mask_16:*i8 = merge{16**0, 16 ** -1}; def tail_mask_v{(16)} = tail_mask_16
tail_mask_32:*i8 = merge{32**0, 32 ** -1}; def tail_mask_v{(32)} = tail_mask_32
def tail_mask{T, i} = load{T, tail_mask_v{vcount{T}}, i}
def mix{x:T} = x *{u16} cycle_make{u16~*T, 0x3343,0xf7a9,0x895b,0x318d}
# def mix{x:T} = x *{u16} cycle_make{u16~*T, 0x3343,0xf7a9,0x895b,0x318d,0x3131,0x99a3,0xe137,0x0734}


def hash_vec64{x:V & eltype{V}==HASH} = { # hash each 64-bit lane, each such being high64^low64
  hv:= x
  if (not is_java) hv = mix{hv}
  hv^= l128_shrb8{hv,4}
  hv^= hv >>{i32} 16
  hv # &{u32} 255 # for testing hash collision behavior
  # hv |{i32} -256
}
def hash_vec{x:V & eltype{V}==i8} = { # hash each 128-bit lane
  def HX = HASH~*V
  hv:= HX~~x
  # if (not is_java) hv = mix{hv}
  hv^= l128_upper_u64{hv}
  hash_vec64{hv}
}
fn hash_1brc_short(arr:*i8) : HASH = extract{hash_vec{load{[exp_bulk]i8, arr, ux~~0}}, 0}
export{'hash_1brc_short', hash_1brc_short}

def st_mask{{hash_mask, map_hash}} = hash_mask
def probe_raw{{hash_mask, map_hash}, hash, idx} = idx + ctz{homMask{hash == load{HASHV, map_hash, idx}}}
def probe{state, hash:(HASH)} = probe_raw{state, hash, cast_i{ux, hash & st_mask{state}}}

def hash_vecs{state, vs} = {
  def {hash_mask, map_hash} = state
  def extract_hashes{v:T} = each{extract{v,.}, range{vcount{T}/4} * 4}
  def probe_one{h} = probe{state, h}
  
  def probe_each{hv:T if exp_bulk==16 and T==[8]HASH} = { # [hash0,?,?,?, hash1,?,?,?] → tup{index of hash0, index of hash1}; unspecified but valid results if not found
    idxv:= hv & hash_mask
    idxs:= each{cast_i{ux,.}, extract_hashes{idxv}}
    hashes:= pair{each{load{HASHV, map_hash, .}, idxs}}
    m:= homMask{hashes == shuf{[8]HASH, hv, 0,0,0,0, 4,4,4,4}}
    m2:= m & (m-1)
    if (rare{m2 == 0}) {
      def {i0,i1} = idxs
      def c = ctz{m}
      idxs = tup{i0+c, i1+c-vcount{HASHV}}
      idxs = each{{i} => i & cast_i{ux,hash_mask}, idxs} # make sure bad results are still valid
    } else {
      idxs = each{{idx,m} => idx+ctz{m}, idxs, tup{m,m2>>vcount{HASHV}}}
    }
    idxs
  }
  def probe_each{hv:(HASH~*[exp_bulk]i8)} = tup{probe_one{extract{hv, 0}}}
  
  def r = each{hash_vec, vs}
  def me{T_idxs, separate_idxs} = {
    if (separate_idxs) join{each{probe_each, r}}
    else each{probe_one, join{each{extract_hashes, r}}}
  }
}

def hash_vecs{state, {a:T,b:T if width{T}==256} if not is_java} = {
  def r = hash_vec64{HASH ~* __xor{...unpack128{a,b}}}
  def els = tup{0,2,1,3}
  def me{T_idxs, separate_idxs} = {
    def extre{v} = each{extract{v, .}, 2*els}
    def idxs = each{cast_i{ux,.}, extre{r & st_mask{state}}}
    def h64 = ofence{sel{[8]u32, r, make{[8]u32,0,2,4,6, 0,2,4,6}}}
    def bc{i} = shuf{[8]u32, h64, i, i, i, i, 4+i, 4+i, 4+i, 4+i}
    each{probe_raw{state, ., .}, each{bc, els}, idxs}
  }
}



def info_long{inp, end} = {
  def should_hash = not is_java
  def lbulk = bulk
  def VL = [lbulk]i8
  start:= end+lbulk
  hashv:= if (should_hash) VL**0 else i32~~0
  cont:u1 = 1
  do {
    start-= lbulk
    def v = load{VL, inp, start-lbulk}
    m:= homMask{v == 10}
    cont = m==0
    if (cont) {
      if (should_hash) hashv^= v
    } else {
      c:= clz{lbulk, m}
      start-= c
      if (should_hash) hashv^= v & tail_mask{VL, c}
    }
  } while (cont)
  def hash_long_vec{x:T & width{T}==128} = {
    r:= extract{hash_vec{x}, 0}
    if (rare{r==0}) r = 1
    r
  }
  def hash_long_vec{x:T & width{T}==256} = hash_long_vec{fold{^, halves{hashv}}}
  tup{start, if (should_hash) hash_long_vec{hashv} else 0}
}

(if (not is_java) {
  fn hash_1brc_long(ptr:*i8) = {
    def {start, hash} = info_long{ptr, ux~~0}
    hash
  }
  export{'hash_1brc_long', hash_1brc_long}
})



def mask_newline{v:T & T==[32]i8} = {
  def V64 = u64~*T
  a:= V64~~v_eq{v, 10}
  l:= if (is_java) l128_upper_u64{a} & cycle_make{V64, -1,0}
  else l128shrb{a, 8}
  a|= v_ne{l, 0}
  if (0) {
    a|= l128_shrb8{a, 1}
    a|= l128_shrb8{a, 2}
    a|= l128_shrb8{a, 4}
    v &~ T~~a
  } else {
    a = tree_fold{|, each{{c}=>a>>c, 4 + 16*range{4}}}
    v & T~~v_eq{T~~a, 0}
  }
}
# def mask_newline{v:T & T==[32]i8} = pair{each{mask_newline, halves{v}}}
def mask_newline{v:T & T==[16]i8} = {
  mc:= homMask{v == 10}
  def mw = width{type{mc}}
  def d = mw - exp_bulk
  
  c:= undefined{ux}
  if (likely{mc!=0}) c = clz{mw, mc}
  else c = exp_bulk + d
  c = ofence{c} - d
  
  v & tail_mask{T, c}
}

def VNI64 = [proc_bulk]i64
def VNI16 = i16~*VNI64
def VNI8  =  i8~*VNI64
def magic = 1 + (10<<16) + (100<<24) # https://curiouscoding.nl/posts/1brc/#parsing-using-a-single-multiplication-does-work-after-all-1-dot-48s
def to_digits{v} = { # convert to digits, mapping '\n' and '.' to 0
  if (is_java) __max{i8}{v -{i8} 48, 0} # no saturating ops
  else __subs{u8}{v, 48}
}
def parse_nums{buf:*i16, inp, bufdata, bufS} = {
  num_idxs:= load{VIX, bufdata, bufS}
  nums:VNI8 = i8~*gather{i64, inp, 1, num_idxs, 1} # each 8-byte group is a number
  
  def low8_64 = l128shufb_ident{VNI8} - cycle{vcount{VNI8}, range{8}} # shuf nums for low byte within i64
  
  
  def {num_off, each16} = {
    # nums     off aligned
    # 01234567     01234567
    # 8.5↩ABCD 0   ^^^^^8.5
    # 12.8↩ABC 8   ^^^^12.8
    # -2.7↩ABC 8   ^^^^-2.7
    # -32.1↩AB 16  ^^^-32.1
    off:= (v_eq{i8}{nums, 46} >>{i32} (24-1 - 3))  &{u64}  (3<<3) # offset of '.', shifted left by 3 (i.e. '1.1'→0, '10.2'→8, '-1.2'→8, '-12.3'→16)
    nums = nums <<{u64} ((5<<3) -{u64} off)
    
    aligned:= to_digits{nums}
    if (is_java) {
      def aligned16 = u16~*aligned
      r:= (aligned16 &{u32} 0xff) * 100
      r+= (aligned16 * 10) >>{u16} 8
      r+= (aligned16 >>{u32} 24)
      tup{2, i16~*r}
    } else if (0) {
      t16:= madd{u8~*aligned, cycle_make{VNI8,  10,1,0,1}}
      t32:= madd{t16,         cycle_make{VNI16, 10,1}}
      tup{2, i16~*t32}
    } else {
      def mullo{a, b} = emit{[4]i64, '_mm256_mul_epi32', a, b}
      r:= mullo{aligned >>{u64} 32, [4]i64**magic} >>{u64} 24 &{u64} 1023
      tup{0, i16~*r}
    }
  }
  
  # negate negative numbers
  neg:= i16~*v_ne{u64}{v_eq{nums, 45}, 0}
  each16n:= each16 ^ neg
  each16n-= neg
  # each16 is now [16]i16~~{num0, *, *, *, num1, *, *, *, num2, *, *, *, num3, *, *, *}
  store{buf, 0, each16n} # make it available for dynamic lookup
  
  {i} => i*4 + num_off
}

def parse_nums{buf:*i16, inp:*i8, bufdata, bufS if is_arm} = {
  def bufc = bufdata+bufS
  
  def {neg, ps} = flip{each{{i} => {
    inpp:= inp + load{bufc,i} + 1
    neg:= load{inpp,0} == 45
    inpp+= promote{ux,neg}
    tup{neg, load{*u32~~inpp, 0}}
  }, range{proc_bulk}}}
  v:= make{[4]u32, ps}
  
  # a.b? ab.c
  #  a.b ab.c
  # 1012 0123
  
  def movev{...vs} = make{[16]u8, (range{16}>>2<<2) + cycle{16,vs}}
  aligned:= sel{[16]u8, v, blend{movev{1,0,1,2}, movev{0,1,2,3}, (v=={u8}46) =={u32} 0x00ff0000}}
  def {ml, mh} = mulw{u32~*to_digits{aligned}, [4]u32**magic}
  res:= i32~*emit{[4]u32, 'vshrn_high_n_u64',
    emit{[2]u32, 'vshrn_n_s64', ml, 24},
    mh, 24
  } &{u32} 1023
  
  res = blend{res, -res, make{[4]i32, each{{v} => -promote{i32,v}, neg}}}
  
  store{*u32~~buf, 0, res}
  {i} => i*2
}

def bufstart{i} = i * bufmax2

def ri = range{interleaved}
fn semisearch(inp:*i8, inpOff:ux, bufdata:*ux, bufEnds:*ux) = {
  def takes = takes0{semi_bulk}
  def bufcs = each{new{ux}, each{bufstart, ri}}
  def inpcs = each{{i} => new{inpOff + i*semi_bulk}, ri}
  @for(i to iter_count{semi_bulk}) {
    def ms0 = if (is_arm) {
      assert{bulk==16 and semi_bulk==32}
      def vecs = join{each{{inpc} => {
        each{{i} => load{[bulk]i8, inp, inpc + i*bulk} == 59, tup{0,1}}
      }, inpcs}}
      def ints = each{{c}=>homMask{...c}, split{4, vecs}}
      join{each{{n} => {
        each{{j} => cast_i{u32, n>>j}, range{2}*semi_bulk}
      }, ints}}
    } else {
      each{{inpc} => homMask{load{[bulk]i8, inp, inpc} == 59}, inpcs}
    }
    
    def ms = each{new, ms0}
    def adv_mask{bufc, inpc, m, j, m0tmp} = {
      m2:= m & (m-1)
      store{bufdata, bufc+j, inpc+ctz{m}} # TODO move to_store to a vectorized add at the end?
      m = m2
    }
    @for_const(j to takes) {
      each{{inpc, bufc, m,m0} => adv_mask{bufc, inpc, m, j, m0}, inpcs, bufcs, ms,ms0}
    }
    
    each{{i, m0, m, bufc, inpc} => {
      pop:= popc{m0}
      if (rare{pop > takes}) { # TODO move to an outer if that checks if any is over?
        bufc+= takes
        do {
          adv_mask{bufc, inpc, m, 0, m0}
          bufc+= 1
        } while (m != 0)
      } else {
        bufc+= pop
      }
      inpc+= semi_bulk*interleaved
    }, ri, ms0, ms, bufcs, inpcs}
  }
  each{store{bufEnds, ., .}, ri, bufcs}
  undefined{void}
}

def dt_sum = 0
def dt_num = 1
def dt_min = 2
def dt_max = 3
def DATA = if (is_java) i64 else i32
fn core_1brc{branchless_fail}(
  ident:i32,
  bufdata:*ux,
  
  hash_mask:HASH, # map length (power of two), minus 1
  
  # indexed by masked hash
  map_exp:*i8,    # chunks of exp_bulk
  map_hash:*HASH, # full hash
  map_data:*DATA, # chunks of 4, offsets are dt_*
  
  inp:*i8,
  inpOff:ux
) : void = @withbufs(object_arr) {
  bufEnds:*ux = object_arr{ux, interleaved}
  
  semisearch(inp, inpOff, bufdata, bufEnds)
  def bufEnd{i} = load{bufEnds, i}
  
  
  
  # preparation for core loop
  semi:ux = 0
  each{{i} => { # find the location of a semicolon
    def buf0 = bufstart{i}
    if (buf0 != bufEnd{i}) semi = load{bufdata, buf0}
  }, ri}
  each{{i} => {
    # set read-past-the-end indices to an invalid (0-char) name
    # won't be found in hashtable, and then to_fail will discard it
    pos:= bufEnd{i}
    @for_const(j to proc_bulk) store{bufdata, pos+j, semi+1}
  }, ri}
  
  
  
  # core proessing loop
  temp_buf:*i16 = object_arr{i16, vcount{VNI16}**0}
  def VX = [exp_bulk]i8
  failbuf:= object_arr{ux, bufmax*interleaved*2}
  failposS:ux = 0
  failposC:ux = 0
  
  @for(buf_i to interleaved) {
    bufS:= bufstart{buf_i}
    bufE:= load{bufEnds, buf_i}
    
    retctr:ux = 0
    def buf_end = makelabel{}
    while (bufS < bufE) { # proc_bulk records per iteration
      # definitions for the below ops
      def maskload{n, ib} = { # load n names & mask each to newline; returns tup{tup{...each_individual_name}, merged_vector_of_them}
        def for_vs{G} = @for_const(j to n) {
          off:= load{bufdata, bufS + ib + j}
          G{load{VX, inp, off-exp_bulk}}
        }
        if (is_java or n==1) {
          def parts = each{ofence, for_vs{mask_newline}}
          tup{parts, pair{parts}}
        } else {
          def total = ofence{mask_newline{pair{for_vs{{x}=>x}}}}
          tup{halves{total}, total}
        }
      }
      def get_exp{idx} = load{VX, map_exp, idx*exp_bulk} # get expected name for index
      
      def left = if (branchless_fail) ofence{bufE-bufS} else 9
      def get_temp{ij} = load{temp_buf, num_off{ij}}
      def store_fail{ij, fail} = { # didn't find ij'th record in map
        if (rare{ij >= (if (branchless_fail) left else bufE-bufS)}) goto{buf_end}
        # log fail, to be processed later (so codegen of the fast path isn't pessimized by the presence of a call here)
        store{failbuf, failposC, load{bufdata, bufS + ij}}
        store{failbuf, failposC+1, cast_i{ux, get_temp{ij}}}
        
        failposC+= promote{ux,fail}<<1 # cmov{fail, 2, ux~~0}
      }
      def update{ij, dataoff} = { # found ij'th record at map index idx
        temp:= promote{DATA, get_temp{ij}}
        def upd{k, G} = {
          def p = tup{map_data, dataoff+k}
          store{...p, G{load{...p}}}
        }
        
        if (is_java) upd{dt_min, __min{., temp}}
        else         upd{dt_min, __max{., -temp}}
        upd{dt_max, __max{., temp}}
        
        upd{dt_sum, {v} => v + temp}
        upd{dt_num, {v} => v + 1}
      }
      
      # hashing & map lookup
      def {loadn, T_hvs, T_idxs, separate_idxs} = if (is_java) tup{
        # Java
        1, # loadn
        [16]i8, # T_hvs
        [16]i8, # T_idxs
        1, # separate_idxs; alternative impl of T_idxs
      } else tup{
        # Native
        1, # loadn
        [if (is_arm) 16 else 32]i8, # T_hvs
        [16]i8, # T_idxs
        1, # separate_idxs; alternative impl of T_idxs
      }
      def mk{D,H} = {
        def me{T==[16]i8} = H{}
        def me{T==[32]i8} = D{}
      }
      def mk{vs & width{type{select{vs,0}}}==256} = mk{{}=>vs, {}=>join{each{halves,vs}}}
      def mk{vs & width{type{select{vs,0}}}==128} = mk{{}=>each{pair, split{2,vs}}, {}=>vs}
      
      def {partss, totals} = flip{each{maskload{loadn,.}, range{proc_bulk/loadn}*loadn}}
      def r_masked = mk{{} => mk{totals}{[32]i8}, {} => join{partss}}
      
      def r_hvs = hash_vecs{tup{hash_mask,map_hash}, r_masked{T_hvs}}
      def idxs = r_hvs{T_idxs, separate_idxs}
      
      def exps = each{get_exp, idxs}
      
      # number parsing
      def num_off = parse_nums{temp_buf, inp, bufdata, bufS}
      
      # updating
      each{{ij, idx, got, exp} => {
        if (branchless_fail) {
          def bad = unpredictable{got !== exp}
          store_fail{ij, bad}
          update{ij, cmov{bad, placeholder_idx{}*4, idx*4}}
        } else {
          if (likely{got === exp}) update{ij, idx*4}
          else store_fail{ij, 1}
        }
      }, range{proc_bulk}, idxs, join{partss}, exps}
      
      if (one and ++retctr >= 7) return{}
      
      bufS+= vcount{VIX}
    }
    setlabel{buf_end}
  }
  
  # handle fails
  if (not playground) while (failposS < failposC) {
    def end = load{failbuf, failposS}
    def temp = ty_s{load{failbuf, failposS+1}}
    failposS+= 2
    def case{which, start, ...hash} = {
      if (is_java) emit{void, merge{'main.Main.failed_',which}, ident, start, end, temp, ...hash}
      else         emit{void, merge{          'failed_',which},        start, end, temp, ...hash}
    }
    
    def v0 = load{VX, inp, end-exp_bulk}
    m:= homMask{v0 == 10}
    if (likely{m==0}) {
      def {start, hash} = info_long{inp, end}
      if (is_java) case{'long', start}
      else case{'long', start, hash}
    } else {
      c:= clz{exp_bulk, m}
      case{'short', end-c, extract{hash_vec{v0 & tail_mask{VX,c}},0}}
    }
  }
}
export{'core_1brc', core_1brc{0}}
(if (not is_java) export{'core_1brc_branchless_fail', core_1brc{1}})

(if (is_java or playground) {
  fn minibench(ai8:*i8, ai16:*i16, ai32:*i32, ai64:*i64) : void = @withbufs(object_arr) {
    def VI8  = [16]i8;   def VU8  =  u8~*VI8
    def VI16 = i16~*VI8; def VU16 = u16~*VI8
    def VI32 = i32~*VI8; def VU32 = u32~*VI8
    def VI64 = i64~*VI8; def VU64 = u64~*VI8
    @for (i to 1000) {
      def V = VI32
      def arr = match(elwidth{V}) { {(8)}=>ai8; {(16)}=>ai16; {(32)}=>ai32; {(64)}=>ai64 }
      
      def j = i * vcount{V}
      v:= load{V, arr, j}
      # @for_const(i to 32) v = V~~v_eq{v,v}
      # @for_const(i to 32) v = v ^ V ** -1
      # @for_const(i to 32) v = v & (v ^ V ** -1)
      # @for_const(i to 32) v = andnot{v,v}
      # @for_const(i to 1) {
      #   each{{G} => {
      #     each{{T} => {
      #       v = G{T}{v, 2}
      #     }, tup{i8,i16,i32,i64,u8,u16,u32,u64}}
      #   }, tup{+,-,<<,>>,&,|,^}}
      # }
      # v = pair{halves{v}}
      # v = V~~half{gather{i64, ai8, 1, v, 1}, 0}
      # v = V~~v_eq{v, v}
      # f32~*v
      
      store{arr, j, V~~v}
    }
  }
  export{'minibench',minibench}
})
